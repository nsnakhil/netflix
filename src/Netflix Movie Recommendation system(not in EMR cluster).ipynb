{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this Notebook using Pyspark in the my Anaconda environment(Not in EMR cluster) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For proceeding further, you must have installed JDK 8, Apache Spark and PySpark on your local system depending on the\n",
    "OS and successfully run PySpark in your Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Netflix Movie title\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\user\\Desktop\\Distributed and Scalable data eng\\Netflix\\TrainingRatings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = StructType([\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"UserID\", IntegerType(), True),\n",
    "    StructField(\"Ratings\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read \\\n",
    " .schema(schema1) \\\n",
    " .option(\"inferSchema\", \"True\") \\\n",
    " .csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MovieID: integer (nullable = true)\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- Ratings: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|MovieID| UserID|Ratings|\n",
      "+-------+-------+-------+\n",
      "|      8|1744889|    1.0|\n",
      "|      8|1395430|    2.0|\n",
      "|      8|1205593|    4.0|\n",
      "|      8|1488844|    4.0|\n",
      "|      8|1447354|    1.0|\n",
      "+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3255352"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|           MovieID|           UserID|           Ratings|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|           3255352|          3255352|           3255352|\n",
      "|   mean|  8724.66010434509|1327058.466035931| 3.481187595074204|\n",
      "| stddev|5107.4015117381605|762688.6901278322|1.0828732789156674|\n",
      "|    min|                 8|                7|               1.0|\n",
      "|    max|             17742|          2649285|               5.0|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model-based approach for Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Least Squares model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Ratings\")\n",
    "model = als.fit(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting test data into another dataframe\n",
    "schema2 = StructType([\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"UserID\", IntegerType(), True),\n",
    "    StructField(\"Ratings\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test = r'C:\\Users\\user\\Desktop\\Distributed and Scalable data eng\\Netflix\\TestingRatings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Testing Dataframe\n",
    "df_test = spark.read \\\n",
    " .schema(schema2) \\\n",
    " .option(\"inferSchema\", \"True\") \\\n",
    " .csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|MovieID| UserID|Ratings|\n",
      "+-------+-------+-------+\n",
      "|      8| 573364|    1.0|\n",
      "|      8|2149668|    3.0|\n",
      "|      8|1089184|    3.0|\n",
      "|      8|2465894|    3.0|\n",
      "|      8| 534508|    1.0|\n",
      "+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100478"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Distict Movies and Users in the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|            UserID|             count|\n",
      "+-------+------------------+------------------+\n",
      "|  count|             27555|             27555|\n",
      "|   mean|1325637.6160406459|3.6464525494465616|\n",
      "| stddev| 762738.5020270856|2.3513183230802865|\n",
      "|    min|                 7|                 1|\n",
      "|    max|           2649285|                70|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the count of unique Users\n",
    "df_uniqueUsers = df_test.groupBy(['UserID']).count()\n",
    "df_uniqueUsers.describe().show()\n",
    "# Unique count = 27555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|          MovieID|             count|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|             1701|              1701|\n",
      "|   mean| 8919.66784244562| 59.06995884773662|\n",
      "| stddev|5168.709499952631|121.58856049833442|\n",
      "|    min|                8|                 1|\n",
      "|    max|            17742|               811|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the count of unique Movies in testing data\n",
    "df_uniqueMovies = df_test.groupBy(['MovieID']).count()\n",
    "df_uniqueMovies.describe().show()\n",
    "#Unique count = 1701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------+\n",
      "|MovieID| UserID|Ratings|prediction|\n",
      "+-------+-------+-------+----------+\n",
      "|    218|2302897|    4.0|  7.535534|\n",
      "|  15480|1460800|    4.0|  5.914879|\n",
      "|  12700|2173152|    4.0|  5.899558|\n",
      "|  14283|1229656|    5.0| 5.8130255|\n",
      "|  14808| 942442|    5.0|  5.800982|\n",
      "|  14808|1178384|    3.0| 5.7909117|\n",
      "|  12293| 304581|    5.0|  5.781457|\n",
      "|  12184|1909349|    5.0|  5.780202|\n",
      "|    844|2387369|    5.0| 5.7670455|\n",
      "|  16902|   5980|    3.0|  5.765463|\n",
      "|   1848| 761430|    5.0|  5.762156|\n",
      "|  16707|1823836|    5.0| 5.7180157|\n",
      "|   8933| 117581|    4.0| 5.7034674|\n",
      "|   6281|2510301|    5.0| 5.6293592|\n",
      "|   7400|1952860|    5.0| 5.6181192|\n",
      "|  12293|1001464|    5.0| 5.6138134|\n",
      "|   2430|1019603|    5.0| 5.5977087|\n",
      "|   7505|2429098|    5.0|  5.596356|\n",
      "|   9689| 735560|    5.0| 5.5950675|\n",
      "|  16022| 657521|    5.0|   5.59129|\n",
      "+-------+-------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the predictions made using metrics : Root Mean Squared Error and Absolute Mean Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root means quare error = 0.8493166767705578\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Ratings\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root means quare error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error = 0.6668206177535538\n"
     ]
    }
   ],
   "source": [
    "evaluator_2 = RegressionEvaluator(metricName=\"mae\", labelCol=\"Ratings\",predictionCol=\"prediction\")\n",
    "mae = evaluator_2.evaluate(predictions)\n",
    "print(\"Mean Absolute Error = \" + str(mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adding a new user. Let it be the user '1' and let's say I have watched 10 movies and did rating them.I have manually \n",
    "added in Training set and creating a new dataframe. I'll be outputing predictions for the movies I haven't watched. \"\"\"\n",
    "\n",
    "file_path_addedUser1 = r'C:\\Users\\user\\Desktop\\Distributed and Scalable data eng\\Netflix\\TrainingRatings_addedUser1.txt'\n",
    "df_train_addedUser1 = spark.read \\\n",
    " .schema(schema1) \\\n",
    " .option(\"inferSchema\", \"True\") \\\n",
    " .csv(file_path_addedUser1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+\n",
      "|summary|          MovieID|            UserID|           Ratings|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "|  count|          3255362|           3255362|           3255362|\n",
      "|   mean| 8724.63380048056|1327054.3895078336|3.4811864241211885|\n",
      "| stddev|5107.415718447187| 762691.0652031554|1.0828736515089448|\n",
      "|    min|                8|                 1|               1.0|\n",
      "|    max|            17742|           2649285|               5.0|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_addedUser1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|UserID|MovieID|Ratings|\n",
      "+------+-------+-------+\n",
      "|     1|     69|    4.0|\n",
      "|     1|     91|    4.0|\n",
      "|     1|     76|    3.0|\n",
      "|     1|    129|    2.0|\n",
      "|     1|    152|    1.0|\n",
      "|     1|    183|    3.0|\n",
      "|     1|    192|    4.0|\n",
      "|     1|    204|    5.0|\n",
      "|     1|    233|    3.0|\n",
      "|     1|    289|    2.0|\n",
      "+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_1 = df_train_addedUser1.filter(df_train_addedUser1['UserID']==1).select(['UserID','MovieID','Ratings'])\n",
    "user_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = als.fit(df_train_addedUser1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model2.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+----------+\n",
      "|MovieID| UserID|Ratings|prediction|\n",
      "+-------+-------+-------+----------+\n",
      "|    218|2302897|    4.0|  6.608642|\n",
      "|   6991|1390768|    4.0| 6.1331286|\n",
      "|  16902|   5980|    3.0|  5.923931|\n",
      "|   8561| 685113|    5.0| 5.8187985|\n",
      "|  10578|1476006|    5.0|  5.794419|\n",
      "|   6756|2614232|    5.0| 5.7690296|\n",
      "|  12184|1909349|    5.0| 5.7673874|\n",
      "|  12232|2617068|    5.0|  5.711573|\n",
      "|  14808|1178384|    3.0|  5.701107|\n",
      "|   3824|1663569|    5.0|  5.676264|\n",
      "|   8933| 117581|    4.0| 5.6736484|\n",
      "|  14808| 942442|    5.0| 5.6624107|\n",
      "|   1848| 761430|    5.0| 5.6581693|\n",
      "|    359| 501823|    5.0|  5.640541|\n",
      "|  10947|1783036|    5.0|  5.629932|\n",
      "|  16707|1823836|    5.0|  5.629205|\n",
      "|  12293| 304581|    5.0| 5.6265254|\n",
      "|  15183|1391668|    5.0| 5.6258717|\n",
      "|   3928| 753532|    5.0| 5.6249366|\n",
      "|  15183|1476102|    4.0|  5.617443|\n",
      "+-------+-------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Obtaining the top 10 recommendations for the UserID = 1 \n",
    "recommendations.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Movie titles into another dataframe\n",
    "schema3 = StructType([\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"YearOfRelease\", IntegerType(), True),\n",
    "    StructField(\"MovieName\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_titles_df = spark.read \\\n",
    " .schema(schema3) \\\n",
    " .option(\"inferSchema\", \"True\") \\\n",
    " .csv(r'C:\\Users\\user\\Desktop\\Distributed and Scalable data eng\\Netflix\\movie_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+--------------------+\n",
      "|MovieID|YearOfRelease|           MovieName|\n",
      "+-------+-------------+--------------------+\n",
      "|      1|         2003|     Dinosaur Planet|\n",
      "|      2|         2004|Isle of Man TT 20...|\n",
      "|      3|         1997|           Character|\n",
      "|      4|         1994|Paula Abdul's Get...|\n",
      "|      5|         2004|The Rise and Fall...|\n",
      "+-------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_titles_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|YearOfRelease|           MovieName|\n",
      "+-------------+--------------------+\n",
      "|         1983|Triumph: Live at ...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " movies_titles_df.filter(movies_titles_df['MovieID']==218).select(['YearOfRelease','MovieName']).show()\n",
    "# Triumph is the first movie recommended to me with high prediction Rating.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
